

<!doctype html>
<html lang="en" class="no-js">
  <head>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D05KGYYBCL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-D05KGYYBCL');
</script>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>[Paper Review] Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World (CaCao) - Sangoh Kim</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Sangoh Kim">
<meta property="og:title" content="[Paper Review] Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World (CaCao)">


  <link rel="canonical" href="http://localhost:4000/posts/2024/12/CaCao-paper-review/">
  <meta property="og:url" content="http://localhost:4000/posts/2024/12/CaCao-paper-review/">



  <meta property="og:description" content="BERT 기반 data augmentation을 이용하여 scene graph generation 분야의 predicate imbalance 문제를 개선한 연구입니다.">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2024-12-26T00:00:00-08:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Sangoh Kim",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Sangoh Kim Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>


<!-- Support for MatJax -->
<script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<!-- end custom head snippets -->

    
	    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
  }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Sangoh Kim</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/year-archive/">Blog Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/files/241230_SangohKim_CV_2.pdf">CV</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/profile.png" class="author__avatar" alt="Sangoh Kim">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Sangoh Kim</h3>
    <p class="author__pronouns">he/his</p>
    <p class="author__bio">Undergraduate Student, Computer Science</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      <!-- Font Awesome icons / Biographic information  -->
      
        <li><i class="fa-solid fa-location-dot icon-pad-right" aria-hidden="true"></i>Daejeon, South Korea</li>
      
      
        <li><i class="fa fa-solid fa-building-columns icon-pad-right" aria-hidden="true"></i>KAIST</li>
      
      
      
        <li><a href="mailto:tkddh1109 (at) kaist.ac.kr"><i class="fas fa-fw fa-envelope icon-pad-right" aria-hidden="true"></i>Email</a></li>
      

      <!-- Font Awesome and Academicons icons / Academic websites -->
            
      
      
      
                              
      

      <!-- Font Awesome icons / Repositories and software development -->
      
            
            
      
        <li><a href="https://github.com/sangohkim"><i class="fab fa-fw fa-github icon-pad-right" aria-hidden="true"></i>Github</a></li>
      
            
            

      <!-- Font Awesome icons / Social media -->
      
      
            
      
                  
                  
      
            
            
      
        <li><a href="https://www.linkedin.com/in/sangoh-kim-9395282b9"><i class="fab fa-fw fa-linkedin icon-pad-right" aria-hidden="true"></i>LinkedIn</a></li>
            
      
            
                  
            
      
            
            
      
        <li><a href="https://twitter.com/rlatkddh1"><i class="fab fa-fw fa-x-twitter icon-pad-right" aria-hidden="true"></i>X (formerly Twitter)</a></li>
      
              
      
                      
      
      
            
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="[Paper Review] Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World (CaCao)">
    <meta itemprop="description" content="BERT 기반 data augmentation을 이용하여 scene graph generation 분야의 predicate imbalance 문제를 개선한 연구입니다.">
    <meta itemprop="datePublished" content="December 26, 2024">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">[Paper Review] Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World (CaCao)
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  6 minute read
	
</p>
          
        
        
        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2024-12-26T00:00:00-08:00">December 26, 2024</time></p>
            
        </header>
      

      <section class="page__content" itemprop="text">
        <p>BERT 기반 data augmentation을 이용하여 scene graph generation 분야의 predicate imbalance 문제를 개선한 연구입니다.</p>

<hr />

<h1 id="motivation">Motivation</h1>

<p>Scene Graph Generation 분야에서는 predicate imbalance 문제가 주요 연구 주제 중 하나입니다.
Predicate imbalance 는 Visual Genome 등의 SGG 학습 데이터셋에서, informative/fine-grained predicate을 포함한
triplet이 frequent/coarse-grained predicate을 포함한 triplet에 비해 적은 현상을 의미합니다.
아래 왼쪽 그래프에서 확인할 수 있듯이, on/has와 같은 coarse-grained predicate의 개수가
carrying/laying on과 같은 fine-grained predicate 보다 압도적으로 많습니다.</p>

<p align="center">
 <img src="/images/paper-review-CaCao-long-tail.png" height="500px" width="800px" />
</p>

<p>위와 같은 predicate의 long-tail distribution은, SGG 모델 성능 하락의 큰 원인이 됩니다.
Predicate imbalance로 인해, 모델이 대부분의 relationship을 on, has와 같은 coarse-grained predicate으로 예측해버리는 현상이 나타나는 것입니다.
위 오른쪽 그래프에서, 모델의 예측성능(Recall@K)이 fine-grained predicate에 대해서는 매우 낮은 것을 확인할 수 있습니다.</p>

<p>Predicate imbalance 문제를 해결하기 위해 여러 방법론이 제안되었습니다.
대표적으로 causality에 기반한 <a href="https://arxiv.org/abs/2002.11949">TDE</a>, reweighting에 기반한 <a href="https://arxiv.org/abs/1812.01880">VCTree</a>가 있습니다.</p>

<p>위와 같은 여러 선행연구에서 여러가지 방법으로 predicate imbalance에 보다 robust한 SGG 모델을 학습할 수 있음을 보였지만, 
본 논문에서는 기존 선행연구들의 한계점을 아래와 같이 지적하였습니다.</p>
<ul>
  <li>대부분이 hand-designed rule에 기반하여 unscalable하다.</li>
  <li>Source data, model architecture에 따라 hyperparameter의 세밀한 조정이 필요하다.</li>
  <li>Prior data distribution에 의존한다.</li>
</ul>

<p>이러한 한계점에서 벗어나기 위해, 저자는 pretrained language model (BERT)의 extensive knowledge 사용을 제안하였습니다.
Large-scale dataset에서 사전학습된 언어 모델이 informative relationship에 대한 정보를 잘 알고 있을 것이라는 가정에 기반한 것입니다.</p>

<p>이를 위해 BERT에 기반하여 기존 데이터셋에서 tail predicate이 포함된 triplet을 증강해주는 
<strong>C</strong>ross-mod<strong>a</strong>l predi<strong>Ca</strong>te b<strong>o</strong>osting (<strong>CaCao</strong>) data augmentation framework를 제안하였습니다.
CaCao를 통해 Visual Genome 등의 기존 데이터셋을 증강하고, 이를 SGG 모델의 학습에 이용하여 성능을 개선하는 방식입니다.</p>

<h1 id="key-idea">Key Idea</h1>

<p align="center">
 <img src="/images/paper-review-CaCao-framework.png" height="500px" width="500px" />
</p>

<p>CaCao framework는 내부적으로 BERT 기반의 Visually-Prompted Language Model을 가지고 있으며,
COCO 데이터셋의 image, triplet pair로 Visually-Prompted Language Model을 학습합니다.
이후 학습이 완료된 모델을 이용해 기존 데이터셋의 unlabeled object pair에 대한 labeling을 진행하여 데이터셋을 증강하게 됩니다.
Unlabeled object pair는 Visual Genome을 예로 들면 bounding box coordinate을 이용하여 object 간의 IoU를 계산한 후,
특정값 이상이며 아직 레이블링 되어있지 않은 조합을 의미합니다.</p>

<p>COCO 데이터셋의 경우 저자가 uninformative, frequent predicate을 제거하는 전처리를 적용하여
585 종류의 informative predicate을 가지고 있는 상태입니다. 따라서 이 데이터셋을 학습한 Visually-Prompted Language Model은
informative predicate을 예측할 수 있게 됩니다.
단, COCO 데이터셋과 Visual Genome 등의 SGG 데이터셋의 label은 다릅니다. 따라서 데이터셋 증강 시에는
모델이 COCO의 informative predicate으로 예측하면 이를 증강하는 데이터셋의 적절한 label과 mapping하게 됩니다.</p>

<h2 id="visually-prompted-language-model">Visually-Prompted Language Model</h2>

<p align="center">
 <img src="/images/paper-review-VPLM.png" height="700px" width="500px" />
</p>

<p>Visually-Prompted Language Model의 내부적인 구조는 위와 같습니다.
Pre-trained Language Model은 Frozen BERT를 의미하며, Image Encoder는 Frozen ViT를 이용합니다.
모델이 내부적으로 학습하는 것은 오직 Visual Transformation Layer 및 Textual prompt 입니다.</p>

<p>Visual Transformation Layer는 image, text 간의 modality gap을 해소하기 위해 도입되었습니다.
BERT는 원래 언어 정보만 인식할 수 있어, SGG에 필요한 visual feature를 직접 제공할 수 없습니다.
따라서 visual feature를 text modality로 변환시키는 Visual Transformation Layer를 도입하여
이미지 정보를 함께 프롬프트로 제공하게 됩니다. 
Visual Transformation Layer는 내부적으로 MultiheadAttention, Feed Forward로 구성된 하나의 self attention module로 구현되어 있습니다.</p>

<p>Textual propmt는 정확한 용도를 제가 이해하지는 못했지만(논문에서는 efficient text prompt engineering을 위해서 도입되었다고 합니다)
보다 visual information과 text가 잘 융합되도록 해주는 역할로 생각하고 넘어갔습니다. 구현 상에서는 learnable token 10개로 구성하였습니다.</p>

<p>Visually-Prompted Language Model의 inference 과정은</p>
<ol>
  <li>Image Encoder &amp; Visual Transformation Layer, PLM Embedding Layer가 각각 image, triplet (e.g. [apple][MASK][table])을 prompt로 인코딩합니다.</li>
  <li>이후 textual prompt와 concatenation을 진행하여 전체 prompt를 완성한 후 BERT에 전달합니다.</li>
  <li>BERT는 제공받은 prompt를 처리합니다.</li>
  <li>BERT의 마지막 layer의 embedding 값을 classifier (linear layer)에 전달하여 최종 logit을 계산합니다.</li>
  <li>Logit 값을 이용해서 [MASK] 자리에 알맞는 predicate을 예측합니다.</li>
</ol>

<p>이제 Visually-Propmted Language Model의 training에 대해서 다루어보겠습니다.
Training 과정에서 학습하는건 visual transformation layer, textual propmt 입니다.
모델이 image, triplet pair를 제공받으면, 위 inference 과정과 동일하게 동작하고 최종적으로 logit을 도출해 냅니다.
이후에 logit에 softmax를 적용한 후 변형된 cross entropy loss로 학습을 진행합니다.
하나의 (image, triplet) pair에 대해서 objective는 아래와 같이 정의됩니다.</p>

<h2 id="adaptive-semantic-cluster-loss-ascl">Adaptive Semantic Cluster Loss (ASCL)</h2>

\[-\min \Sigma^{N_p}_{i=1} \mathop{\mathbb{E}}_\epsilon[\phi(y_i) + \Sigma _{j \in C_i} \frac{\epsilon_{i, j}}{|C_i|} \phi(y_j)] \log \psi(y_i | X_i)\]

<p>여기서 $\psi(y_i | X_i)$ 는 input prompt $X_i$ 의 masked position에 대한 probability distribution 입니다. $\phi(y_i)$ 는
ground-truth label을 나타내는 one-hot vector를 의미합니다.</p>

\[\mathop{\mathbb{E}}_\epsilon[\phi(y_i) + \Sigma _{j \in C_i} \frac{\epsilon_{i, j}}{|C_i|} \phi(y_j)]\]

<p>일반적인 cross entropy loss의 경우 위 부분이 $\phi(y_i)$ 여야 하지만 CaCao에서는 이를 조금 변형하여 사용합니다.
Predicate은 그 종류가 매우 다양하기 때문에 철자가 서로 다른 predicate이라도, 문맥상 비슷한 의미를 가지고 있는 경우가 있습니다(논문에서는 이를 semantic co-reference라고 부릅니다).
그러나 위 objective에 $\phi(y_i)$ 만을 사용한다면 예를 들어 ‘on’이 정답인 triplet에 대해 ‘above’라는 예측을 하였을 경우,
어느정도 비슷함에도 아예 다른 예측을 하였을 때와 동일하게 penalize 됩니다. 그렇게 된다면, 모델의 학습이 어려워지고 augmentation에 필요한 diversity를 얻기에도 어려워집니다.</p>

<p>이를 개선하기 위해 CaCao의 학습에는 위와 같은 loss가 사용됩니다 (Adaptive Semantic Cluster Loss라고 논문에서 부릅니다).
Loss 계산 방식은 우선 COCO 데이터셋의 predicate 별로 embedding을 계산합니다. Embedding은 &lt;subject-predicate-object&gt; 형태의 triplet이 있을 때,
이를 BERT에 넣고 마지막 layer의 embedding을 가져옵니다. 특정 predicate이 포함된 모든 triplet에 대해 동일하게 embedding을 계산하고 이를 평균 내주면
해당 predicate의 임베딩이 되는 방식입니다.</p>

<p>이후 predicate embedding 전체에 대해 K-Means Clustering을 진행합니다. 클러스터의 개수는 논문의 구현 상에서는 39로 하였으나 해당 값으로 결정하게 된 
근거는 찾지 못하였습니다. 클러스터링 이후 특정 label $y_i$ 에 대해서 $y_i$ 와 동일한 클러스터 내부에 있는 레이블을 함께 고려해주도록 하는 것이 위 수식의 의미가 됩니다.
같은 클러스터에 있는 다른 label에는 $\frac{\epsilon_{i, j}}{|C_i|}$ 만큼의 가중치가 붙는데 $\epsilon_{i, j}$는 i, j predicate embedding 간의 
cosine similarity 값을 의미합니다.</p>

<p>저자는 위 방식을 통해, 모델이 최대한 다양한 informative predicate을 예측하도록 유도할 수 있다고 주장하였습니다. 이를 위해서, $\psi(y_i | X_i)$ 도 일반적인
softmax에서 조금 변형하였습니다.</p>

\[\psi(y_i | X_i) = \frac{\exp({z_i})}{\Sigma_{j=1}^{K} w_{i, j}\exp({z_j})} \ w_{i, j} = \delta \frac{z_j}{z_i} \frac{n_j}{n_i}\]

<p>$z_i, z_j$는 logit 값을 의미하며 $n_i, n_j$는 i, j predicate의 초기 개수는 의미합니다. 위의 변형된 softmax를 통해 모델이 특정 predicate 만 과도하게
생성하는 것을 방지할 수 있었다고 합니다.</p>

<h2 id="epic">Epic</h2>

<p>CaCao를 이용하면 데이터셋을 효과적으로 증강한 후에 <a href="https://arxiv.org/abs/1701.02426">IMP</a>, <a href="https://arxiv.org/abs/1711.06640v2">Motifs</a>
등의 SGG 모델의 학습에 이용할 수 있습니다. 논문에서는 더 나아가 Open-World Predicate SGG 모델 구조를 제안하였습니다. 
<strong>E</strong>ntangled cross-modal <strong>p</strong>rompt approach for open-world pred<strong>i</strong>cate s<strong>c</strong>ene graph generation (Epic)으로 명명되며 
구조는 아래와 같습니다.</p>

<p align="center">
 <img src="/images/paper-review-CaCao-epic.png" height="500px" width="800px" />
</p>

<h1 id="experiments">Experiments</h1>

<p align="center">
 <img src="/images/paper-review-CaCao-Exp.png" height="500px" width="800px" />
</p>

<p>주요 SGG 모델을 CaCao로 학습하였을 때 위와 같이 기존 방법들보다 성능을 향상 시킬 수 있었다고 합니다. 저자는 predicate imbalance에 robust하기 위해
R@K가 아닌 mR@K를 사용하였으며, tail predicate에 대한 성능을 보다 면밀하게 측정할 수 있도록 빈도수 하위 50% predicate에 대해서만 성능을 측정한
Tail-R@K도 사용하였습니다.</p>

<h1 id="conclusion">Conclusion</h1>

<p>Data augmentation을 기반으로 predicate imbalance 문제를 해결한 연구는 있었으나 open world knowledge를 이용한건 본 논문이 처음인듯 합니다.
보통 Open-World SGG 모델을 새로 구축하는 연구들은 꽤 있었는데 Open-World로 데이터셋을 증강하고 closed SGG에 적용하는 접근도 있다는 것을 알게 되었습니다.
추가로, 본 논문의 github에서 확인해보니 클러스터링이 제대로 된 것인지 조금 의문이 들기는 합니다. 클러스터 개수 K도 적절한 것인지, 원소가 하나만 있는 클러스터도 
있던데 괜찮은 것인지, K-Means 이외의 다른 방식은 없는지에 대한 고민을 해보면 좋을 것 같습니다.</p>

<p>읽어주셔서 감사합니다 :)</p>


        

        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/tags/#ai" class="page__taxonomy-item" rel="tag">AI</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#compotisional-generalization" class="page__taxonomy-item" rel="tag">Compotisional Generalization</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#multimodal-learning" class="page__taxonomy-item" rel="tag">Multimodal Learning</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#scene-graph-generation" class="page__taxonomy-item" rel="tag">Scene Graph Generation</a>
    
    </span>
  </p>




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/posts/2024/12/CaCao-paper-review/" class="btn btn--twitter" title="Share on Twitter"><i class="fab fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/posts/2024/12/CaCao-paper-review/" class="btn btn--facebook" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/posts/2024/12/CaCao-paper-review/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="http://localhost:4000/posts/2024/03/imputation-process/" class="pagination--pager" title="[AI] Imputation Process for AI
">Previous</a>
    
    
      <a href="http://localhost:4000/posts/2024/12/ViT-paper-review/" class="pagination--pager" title="[Paper Review] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (ViT)
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      
        <h4 class="page__related-title">You May Also Enjoy</h4>
      
      <div class="grid__wrapper">
        
          





<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/posts/2024/12/ViT-paper-review/" rel="permalink">[Paper Review] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (ViT)
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  9 minute read
	
</p>
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2024-12-29T00:00:00-08:00">December 29, 2024</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>ViT의 구조를 간단히 다루어보고, 논문의 Experiments/Appendix 위주로 리뷰해보았습니다.</p>

</p>
    
    
    

  </article>
</div>

        
          





<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/posts/2024/03/imputation-process/" rel="permalink">[AI] Imputation Process for AI
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  4 minute read
	
</p>
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2024-03-11T00:00:00-07:00">March 11, 2024</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>AI 대회에서 활용하기 위해 여러 imputation 기법들을 정리해보았습니다.</p>

</p>
    
    
    

  </article>
</div>

        
      </div>
    </div>
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/sangohkim"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 Sangoh Kim. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  </body>
</html>

