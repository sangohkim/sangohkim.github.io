<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-12-27T06:47:01-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Sangoh Kim</title><subtitle>Undergraduate student of Korea Advanced Institute of Science and Technology (KAIST)</subtitle><author><name>Sangoh Kim</name><email>tkddh1109 (at) kaist.ac.kr</email></author><entry><title type="html">[Paper Review] Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World (CaCao)</title><link href="http://localhost:4000/posts/2024/12/CaCao-paper-review/" rel="alternate" type="text/html" title="[Paper Review] Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World (CaCao)" /><published>2024-12-26T00:00:00-08:00</published><updated>2024-12-26T00:00:00-08:00</updated><id>http://localhost:4000/posts/2024/12/CaCao-paper-review</id><content type="html" xml:base="http://localhost:4000/posts/2024/12/CaCao-paper-review/"><![CDATA[<p>BERT 기반 data augmentation을 이용하여 scene graph generation 분야의 predicate imbalance 문제를 개선한 연구입니다.</p>

<hr />

<h1 id="motivation">Motivation</h1>

<p>Scene Graph Generation 분야에서는 predicate imbalance 문제가 주요 연구 주제 중 하나입니다.
Predicate imbalance 는 Visual Genome 등의 SGG 학습 데이터셋에서, informative/fine-grained predicate을 포함한
triplet이 frequent/coarse-grained predicate을 포함한 triplet에 비해 적은 현상을 의미합니다.
아래 왼쪽 그래프에서 확인할 수 있듯이, on/has와 같은 coarse-grained predicate의 개수가
carrying/laying on과 같은 fine-grained predicate 보다 압도적으로 많습니다.</p>

<p align="center">
 <img src="/images/paper-review-CaCao-long-tail.png" height="500px" width="800px" />
</p>

<p>위와 같은 predicate의 long-tail distribution은, SGG 모델 성능 하락의 큰 원인이 됩니다.
Predicate imbalance로 인해, 모델이 대부분의 relationship을 on, has와 같은 coarse-grained predicate으로 예측해버리는 현상이 나타나는 것입니다.
위 오른쪽 그래프에서, 모델의 예측성능(Recall@K)이 fine-grained predicate에 대해서는 매우 낮은 것을 확인할 수 있습니다.</p>

<p>Predicate imbalance 문제를 해결하기 위해 여러 방법론이 제안되었습니다.
대표적으로 causality에 기반한 <a href="https://arxiv.org/abs/2002.11949">TDE</a>, reweighting에 기반한 <a href="https://arxiv.org/abs/1812.01880">VCTree</a>가 있습니다.</p>

<p>위와 같은 여러 선행연구에서 여러가지 방법으로 predicate imbalance에 보다 robust한 SGG 모델을 학습할 수 있음을 보였지만, 
본 논문에서는 기존 선행연구들의 한계점을 아래와 같이 지적하였습니다.</p>
<ul>
  <li>대부분이 hand-designed rule에 기반하여 unscalable하다.</li>
  <li>Source data, model architecture에 따라 hyperparameter의 세밀한 조정이 필요하다.</li>
  <li>Prior data distribution에 의존한다.</li>
</ul>

<p>이러한 한계점에서 벗어나기 위해, 저자는 pretrained language model (BERT)의 extensive knowledge 사용을 제안하였습니다.
Large-scale dataset에서 사전학습된 언어 모델이 informative relationship에 대한 정보를 잘 알고 있을 것이라는 가정에 기반한 것입니다.</p>

<p>이를 위해 BERT에 기반하여 기존 데이터셋에서 tail predicate이 포함된 triplet을 증강해주는 
<strong>C</strong>ross-mod<strong>a</strong>l predi<strong>Ca</strong>te b<strong>o</strong>osting (<strong>CaCao</strong>) data augmentation framework를 제안하였습니다.
CaCao를 통해 Visual Genome 등의 기존 데이터셋을 증강하고, 이를 SGG 모델의 학습에 이용하여 성능을 개선하는 방식입니다.</p>

<h1 id="key-idea">Key Idea</h1>

<p align="center">
 <img src="/images/paper-review-CaCao-framework.png" height="500px" width="500px" />
</p>

<p>CaCao framework는 내부적으로 BERT 기반의 Visually-Prompted Language Model을 가지고 있으며,
COCO 데이터셋의 image, triplet pair로 Visually-Prompted Language Model을 학습합니다.
이후 학습이 완료된 모델을 이용해 기존 데이터셋의 unlabeled object pair에 대한 labeling을 진행하여 데이터셋을 증강하게 됩니다.
Unlabeled object pair는 Visual Genome을 예로 들면 bounding box coordinate을 이용하여 object 간의 IoU를 계산한 후,
특정값 이상이며 아직 레이블링 되어있지 않은 조합을 의미합니다.</p>

<p>COCO 데이터셋의 경우 저자가 uninformative, frequent predicate을 제거하는 전처리를 적용하여
585 종류의 informative predicate을 가지고 있는 상태입니다. 따라서 이 데이터셋을 학습한 Visually-Prompted Language Model은
informative predicate을 예측할 수 있게 됩니다.
단, COCO 데이터셋과 Visual Genome 등의 SGG 데이터셋의 label은 다릅니다. 따라서 데이터셋 증강 시에는
모델이 COCO의 informative predicate으로 예측하면 이를 증강하는 데이터셋의 적절한 label과 mapping하게 됩니다.</p>

<h2 id="visually-prompted-language-model">Visually-Prompted Language Model</h2>

<p align="center">
 <img src="/images/paper-review-VPLM.png" height="700px" width="500px" />
</p>

<p>Visually-Prompted Language Model의 내부적인 구조는 위와 같습니다.
Pre-trained Language Model은 Frozen BERT를 의미하며, Image Encoder는 Frozen ViT를 이용합니다.
모델이 내부적으로 학습하는 것은 오직 Visual Transformation Layer 및 Textual prompt 입니다.</p>

<p>Visual Transformation Layer는 image, text 간의 modality gap을 해소하기 위해 도입되었습니다.
BERT는 원래 언어 정보만 인식할 수 있어, SGG에 필요한 visual feature를 직접 제공할 수 없습니다.
따라서 visual feature를 text modality로 변환시키는 Visual Transformation Layer를 도입하여
이미지 정보를 함께 프롬프트로 제공하게 됩니다. 
Visual Transformation Layer는 내부적으로 MultiheadAttention, Feed Forward로 구성된 하나의 self attention module로 구현되어 있습니다.</p>

<p>Textual propmt는 정확한 용도를 제가 이해하지는 못했지만(논문에서는 efficient text prompt engineering을 위해서 도입되었다고 합니다)
보다 visual information과 text가 잘 융합되도록 해주는 역할로 생각하고 넘어갔습니다. 구현 상에서는 learnable token 10개로 구성하였습니다.</p>

<p>Visually-Prompted Language Model의 inference 과정은</p>
<ol>
  <li>Image Encoder &amp; Visual Transformation Layer, PLM Embedding Layer가 각각 image, triplet (e.g. [apple][MASK][table])을 prompt로 인코딩합니다.</li>
  <li>이후 textual prompt와 concatenation을 진행하여 전체 prompt를 완성한 후 BERT에 전달합니다.</li>
  <li>BERT는 제공받은 prompt를 처리합니다.</li>
  <li>BERT의 마지막 layer의 embedding 값을 classifier (linear layer)에 전달하여 최종 logit을 계산합니다.</li>
  <li>Logit 값을 이용해서 [MASK] 자리에 알맞는 predicate을 예측합니다.</li>
</ol>

<p>이제 Visually-Propmted Language Model의 training에 대해서 다루어보겠습니다.
Training 과정에서 학습하는건 visual transformation layer, textual propmt 입니다.
모델이 image, triplet pair를 제공받으면, 위 inference 과정과 동일하게 동작하고 최종적으로 logit을 도출해 냅니다.
이후에 logit에 softmax를 적용한 후 변형된 cross entropy loss로 학습을 진행합니다.
하나의 (image, triplet) pair에 대해서 objective는 아래와 같이 정의됩니다.</p>

<h2 id="adaptive-semantic-cluster-loss-ascl">Adaptive Semantic Cluster Loss (ASCL)</h2>

\[-\min \Sigma^{N_p}_{i=1} \mathop{\mathbb{E}}_\epsilon[\phi(y_i) + \Sigma _{j \in C_i} \frac{\epsilon_{i, j}}{|C_i|} \phi(y_j)] \log \psi(y_i | X_i)\]

<p>여기서 $\psi(y_i | X_i)$ 는 input prompt $X_i$ 의 masked position에 대한 probability distribution 입니다. $\phi(y_i)$ 는
ground-truth label을 나타내는 one-hot vector를 의미합니다.</p>

\[\mathop{\mathbb{E}}_\epsilon[\phi(y_i) + \Sigma _{j \in C_i} \frac{\epsilon_{i, j}}{|C_i|} \phi(y_j)]\]

<p>일반적인 cross entropy loss의 경우 위 부분이 $\phi(y_i)$ 여야 하지만 CaCao에서는 이를 조금 변형하여 사용합니다.
Predicate은 그 종류가 매우 다양하기 때문에 철자가 서로 다른 predicate이라도, 문맥상 비슷한 의미를 가지고 있는 경우가 있습니다(논문에서는 이를 semantic co-reference라고 부릅니다).
그러나 위 objective에 $\phi(y_i)$ 만을 사용한다면 예를 들어 ‘on’이 정답인 triplet에 대해 ‘above’라는 예측을 하였을 경우,
어느정도 비슷함에도 아예 다른 예측을 하였을 때와 동일하게 penalize 됩니다. 그렇게 된다면, 모델의 학습이 어려워지고 augmentation에 필요한 diversity를 얻기에도 어려워집니다.</p>

<p>이를 개선하기 위해 CaCao의 학습에는 위와 같은 loss가 사용됩니다 (Adaptive Semantic Cluster Loss라고 논문에서 부릅니다).
Loss 계산 방식은 우선 COCO 데이터셋의 predicate 별로 embedding을 계산합니다. Embedding은 &lt;subject-predicate-object&gt; 형태의 triplet이 있을 때,
이를 BERT에 넣고 마지막 layer의 embedding을 가져옵니다. 특정 predicate이 포함된 모든 triplet에 대해 동일하게 embedding을 계산하고 이를 평균 내주면
해당 predicate의 임베딩이 되는 방식입니다.</p>

<p>이후 predicate embedding 전체에 대해 K-Means Clustering을 진행합니다. 클러스터의 개수는 논문의 구현 상에서는 39로 하였으나 해당 값으로 결정하게 된 
근거는 찾지 못하였습니다. 클러스터링 이후 특정 label $y_i$ 에 대해서 $y_i$ 와 동일한 클러스터 내부에 있는 레이블을 함께 고려해주도록 하는 것이 위 수식의 의미가 됩니다.
같은 클러스터에 있는 다른 label에는 $\frac{\epsilon_{i, j}}{|C_i|}$ 만큼의 가중치가 붙는데 $\epsilon_{i, j}$는 i, j predicate embedding 간의 
cosine similarity 값을 의미합니다.</p>

<p>저자는 위 방식을 통해, 모델이 최대한 다양한 informative predicate을 예측하도록 유도할 수 있다고 주장하였습니다. 이를 위해서, $\psi(y_i | X_i)$ 도 일반적인
softmax에서 조금 변형하였습니다.</p>

\[\psi(y_i | X_i) = \frac{\exp({z_i})}{\Sigma_{j=1}^{K} w_{i, j}\exp({z_j})} \ w_{i, j} = \delta \frac{z_j}{z_i} \frac{n_j}{n_i}\]

<p>$z_i, z_j$는 logit 값을 의미하며 $n_i, n_j$는 i, j predicate의 초기 개수는 의미합니다. 위의 변형된 softmax를 통해 모델이 특정 predicate 만 과도하게
생성하는 것을 방지할 수 있었다고 합니다.</p>

<h2 id="epic">Epic</h2>

<p>CaCao를 이용하면 데이터셋을 효과적으로 증강한 후에 <a href="https://arxiv.org/abs/1701.02426">IMP</a>, <a href="https://arxiv.org/abs/1711.06640v2">Motifs</a>
등의 SGG 모델의 학습에 이용할 수 있습니다. 논문에서는 더 나아가 Open-World Predicate SGG 모델 구조를 제안하였습니다. 
<strong>E</strong>ntangled cross-modal <strong>p</strong>rompt approach for open-world pred<strong>i</strong>cate s<strong>c</strong>ene graph generation (Epic)으로 명명되며 
구조는 아래와 같습니다.</p>

<p align="center">
 <img src="/images/paper-review-CaCao-epic.png" height="500px" width="800px" />
</p>

<h1 id="experiments">Experiments</h1>

<p align="center">
 <img src="/images/paper-review-CaCao-Exp.png" height="500px" width="800px" />
</p>

<p>주요 SGG 모델을 CaCao로 학습하였을 때 위와 같이 기존 방법들보다 성능을 향상 시킬 수 있었다고 합니다. 저자는 predicate imbalance에 robust하기 위해
R@K가 아닌 mR@K를 사용하였으며, tail predicate에 대한 성능을 보다 면밀하게 측정할 수 있도록 빈도수 하위 50% predicate에 대해서만 성능을 측정한
Tail-R@K도 사용하였습니다.</p>

<h1 id="conclusion">Conclusion</h1>

<p>Data augmentation을 기반으로 predicate imbalance 문제를 해결한 연구는 있었으나 open world knowledge를 이용한건 본 논문이 처음인듯 합니다.
보통 Open-World SGG 모델을 새로 구축하는 연구들은 꽤 있었는데 Open-World로 데이터셋을 증강하고 closed SGG에 적용하는 접근도 있다는 것을 알게 되었습니다.
추가로, 본 논문의 github에서 확인해보니 클러스터링이 제대로 된 것인지 조금 의문이 들기는 합니다. 클러스터 개수 K도 적절한 것인지, 원소가 하나만 있는 클러스터도 
있던데 괜찮은 것인지, K-Means 이외의 다른 방식은 없는지에 대한 고민을 해보면 좋을 것 같습니다.</p>

<p>읽어주셔서 감사합니다 :)</p>]]></content><author><name>Sangoh Kim</name><email>tkddh1109 (at) kaist.ac.kr</email></author><category term="AI" /><category term="Scene Graph Generation" /><category term="Multimodal Learning" /><category term="Compotisional Generalization" /><summary type="html"><![CDATA[BERT 기반 data augmentation을 이용하여 scene graph generation 분야의 predicate imbalance 문제를 개선한 연구입니다.]]></summary></entry><entry><title type="html">[AI] Imputation Process for AI</title><link href="http://localhost:4000/posts/2024/03/imputation-process/" rel="alternate" type="text/html" title="[AI] Imputation Process for AI" /><published>2024-03-11T00:00:00-07:00</published><updated>2024-03-11T00:00:00-07:00</updated><id>http://localhost:4000/posts/2024/03/imp-process-ai</id><content type="html" xml:base="http://localhost:4000/posts/2024/03/imputation-process/"><![CDATA[<h1 id="imputation-프로세스">Imputation 프로세스</h1>

<blockquote>
  <p>2024.03.10
LG-Aimers 4기에 참가하면서 결측치 처리에 대한 저만의 명확한 프로세스가 없다는 것을 깨달았습니다. 물론 다양한 데이터셋에 따라 적절히 여러 방식을 적용하는 것이 필요하지만 어느정도 체계를 잡고 싶은 생각에 결측치 처리 방법 및 프로세스를 정리하였습니다.</p>

</blockquote>

<h1 id="결측값의-유형">결측값의 유형</h1>

<blockquote>
  <p>데이터가 결측될 확률에 따라 아래와 같이 3가지로 분류합니다.
현실적으로 실제 상황에서 결측치를 아래 3가지 중 하나로 명확히 분류하는 것은 어려운 것 같습니다.</p>

</blockquote>

<h2 id="mcar-missing-completely-at-random">MCAR (Missing Completely At Random)</h2>

<p>데이터가 결측될 확률이 모든 경우에서 같을 때 MCAR로 분류합니다. 즉 다른 feature가 어떤 값을 가지든, 혹은 결측된 데이터의 값이 어떻든 결측될 확률에 영향을 주지 않는 경우를 의미합니다.</p>

<ul>
  <li>데이터를 기입하는 과정에서 실수로 누락시켰거나 전산 오류가 발생하여 기입되지 않은 경우가 MCAR에 해당합니다.</li>
  <li>결측 원인이 데이터셋의 다른 값들과 전혀 영향이 없기 때문에 다른 feature, 같은 feature 내의 관측된 값으로 imputation을 진행하거나 결측된 데이터를 제거해주시면 됩니다.</li>
  <li>가장 이상적이며 편리한 경우입니다.</li>
</ul>

<h2 id="mar-missing-at-random">MAR (Missing At Random)</h2>

<p>데이터가 결측될 확률이 같은 feature 내의 observed data 내에서 동일한 경우에 MAR로 분류합니다. 즉 다른 feature의 값에 따라 데이터가 결측될 확률이 높아지거나, 낮아질 수 있지만 결측된 값과는 관련이 없을 때를 의미합니다.</p>

<ul>
  <li>몸무게를 측정할 때 젊은 여성 군집에서 몸무게 결측값이 많이 나온 경우 MAR로 분류할 수 있습니다.</li>
</ul>

<h2 id="mnar-missing-not-at-random">MNAR (Missing Not At Random)</h2>

<p>MCAR, MAR이 아닌 경우에 MNAR 또는 NMAR이라고 합니다. 즉 데이터가 결측될 확률이 다른 feature의 값, 결측된 그 자신의 값 또는 데이터셋에 기록되지 않은 외부 요인의 영향을 받을 경우를 의미합니다.</p>

<ul>
  <li>흡연 여부를 선택할 때 실제 흡연자가 사회적 인식을 고려해 사실대로 응답하지 않고 응답란을 비워두는 경우가 예시가 될 수 있습니다</li>
</ul>

<h2 id="mar-mcar-mnar-인지-판단하기">MAR, MCAR, MNAR 인지 판단하기</h2>

<p>결측값이 MAR, MCAR, MNAR인지 구분해주는 명확한 방법은 없습니다. 우선 모든 결측값을 MNAR이라고 기본적으로 가정한 뒤, 데이터셋에 대해서 알고 있는 사전 정보, 데이터셋 수집 방법을 통해 MAR, MCAR을 구분해 나가야 합니다.</p>

<p>데이터의 결측여부를 레이블로 하는 Logistic Regression 모델을 fitting해보는 방식으로 insight를 얻을 수도 있습니다. 결측 여부와 관련이 있는 feature를 찾게 된다면 MAR일 가능성이 높고 그렇지 않다면 MCAR, MNAR 중에서 구분하는 방식으로 판단해볼 수 있습니다.</p>

<h2 id="mar-mcar-mnar에-따른-처리-방법">MAR, MCAR, MNAR에 따른 처리 방법</h2>

<h3 id="mcar인-경우">MCAR인 경우</h3>

<p>Complete case analysis (결측값이 없는 샘플만 남겨놓기) 또는 Simple Imputation, Multiple Imputation 등등 적절히 imputation 방법을 적용하면 됩니다.</p>

<h3 id="mar인-경우">MAR인 경우</h3>

<p>MCAR만틈 valid하지 않지만 complete case analysis도 적용 가능합니다. Simple Imputation도 적용가능하며 Multiple Imputation또한 valid 합니다.</p>

<h3 id="mnar인-경우">MNAR인 경우</h3>

<p>결측값이 발생한 외부적인 요인이 없는지 여부를 조사하고 결측값에 대한 모델링이 필요합니다. 그리고 모델링 후 Multiple Imputation을 적용해볼 수 있습니다. 그러나 MNAR 결측값은 사실상 데이터셋 내부의 정보로 제대로 처리할 수 없기 때문에 일반적으로 MNAR 결측값인 경우 MAR로 가정하고 처리하는 것이 좋을 것 같습니다.</p>

<h1 id="결측값-처리-방법">결측값 처리 방법</h1>

<aside>
💡 MCAR, MAR로 가정하였습니다.

</aside>

<h2 id="결측값의-비율-확인하기-공식적인-가이드라인이-아닙니다">결측값의 비율 확인하기 (공식적인 가이드라인이 아닙니다!)</h2>

<table>
  <thead>
    <tr>
      <th>결측 비율</th>
      <th>처리 방법</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>~10%</td>
      <td>제거하기 또는 여러 방법의 imputation 적용하기</td>
    </tr>
    <tr>
      <td>10% ~ 20%</td>
      <td>Hot deck (KNN Imputation 등등), Regression, Model-based method imputation</td>
    </tr>
    <tr>
      <td>20% ~ 50%</td>
      <td>Model-based method, Regression imputation</td>
    </tr>
    <tr>
      <td>50% ~</td>
      <td>해당 feature 제거하기</td>
    </tr>
  </tbody>
</table>

<h2 id="0-결측값-그대로-두기">0. 결측값 그대로 두기</h2>

<p>결측 비율이 그리 크지 않고 XGBoost, LightGBM과 같이 결측치를 자동으로 처리하는 기능을 제공하는 모델을 사용하는 경우 그대로 두는 것도 하나의 방법이 될 수 있습니다.</p>

<h2 id="1-결측값-제거하기">1. 결측값 제거하기</h2>

<p>데이터셋에 따라 편향, 분산을 고려하여 적절한 방법을 사용해야 합니다.</p>

<ul>
  <li>결측치가 너무 많은 feature 제거하기</li>
  <li>결측치가 있는 row 제거하기</li>
</ul>

<h2 id="2-imputation">2. Imputation</h2>

<h3 id="2-1-simple-imputation">2-1. Simple Imputation</h3>

<p>단일 측정값을 이용해서 결측값을 대체하는 방법입니다. 구현이 간단하고 Multiple Imputation에 비해 처리 시간이 빠르고 자원을 많이 요구하지 않는다는 장점이 있습니다. Imputation을 할 때 가장 기본적으로 적용시켜보는 방법이며 더 복잡한 Imputation이 필요할 때 Multiple Imputation을 사용합니다.</p>

<ul>
  <li>mean, median, most frequent imputation</li>
  <li>constant imputation
    <ul>
      <li>0, -1 로 채우기 등등</li>
    </ul>
  </li>
  <li>KNN imputation
    <ul>
      <li>sklearn KNNImputer 이용하기</li>
      <li>outlier에 민감하므로 이상치를 미리 확인해보는 작업이 필요할 것 같음</li>
    </ul>
  </li>
</ul>

<h3 id="2-2-multiple-imputation">2-2. Multiple Imputation</h3>

<aside>
💡 MICE 외에도 MVNI 기법이 있지만 우선은 MICE에 대해서 알아보고 나머지는 추후에 알아보도록 하겠습니다.

</aside>

<p>Simple Imputation을 여러번 반복하여 결측값을 채우는 방법. 일종의 앙상블이라고 생각하면 됩니다. 결측비율이 꽤 높거나, MAR, MNAR에 가깝다고 생각되는 feature에 대해 적절히 적용하면 좋을 것 같습니다.</p>

<p><img src="/docs/AI/Untitled.png" alt="[Stef van Buuren, Karin Groothuis-Oudshoorn (2011). “mice: Multivariate Imputation by Chained Equations in R”. Journal of Statistical Software](https://www.jstatsoft.org/article/view/v045i03)" /></p>

<p><a href="https://www.jstatsoft.org/article/view/v045i03">Stef van Buuren, Karin Groothuis-Oudshoorn (2011). “mice: Multivariate Imputation by Chained Equations in R”. Journal of Statistical Software</a></p>

<ul>
  <li>MICE의 절차
    <ol>
      <li>데이터셋 생성(imputed data): 결측치를 특정 strategy를 이용해서 모두 대체한 데이터셋을 m개 생성합니다.</li>
      <li>분석과 추정: 임의로 결측값을 대체한 데이터셋을 estimator로 분석합니다.</li>
      <li>추정치 합치기</li>
    </ol>
  </li>
  <li>IterativeImputer
    <ul>
      <li>scikit-learn에서 MICE에 영감을 받아 구현된 imputer</li>
      <li>MICE 방식을 거의 동일하게 적용할 수 있음</li>
    </ul>
  </li>
</ul>

<h3 id="2-3-deep-learning-datawig-이용하기">2-3. Deep Learning (DataWig) 이용하기</h3>

<p>AWSLAB에서 <a href="https://dl.acm.org/citation.cfm?id=3272005">Biessmann, Salinas et al. 2018</a>를 이용하여 구축한 imputation 패키지입니다.. 범주형 특성에도 적용이 가능하며 다른 방식에 비해 비교적 정확하다고 합니다.. 추후 캐글에서 사용하며 구체적인 방식을 알아보겠습니다.</p>]]></content><author><name>Sangoh Kim</name><email>tkddh1109 (at) kaist.ac.kr</email></author><category term="AI" /><category term="Imputation" /><summary type="html"><![CDATA[Imputation 프로세스]]></summary></entry><entry><title type="html">[AI] LG-Aimers 참가 후기</title><link href="http://localhost:4000/posts/2024/03/lg-aimers-review/" rel="alternate" type="text/html" title="[AI] LG-Aimers 참가 후기" /><published>2024-03-02T00:00:00-08:00</published><updated>2024-03-02T00:00:00-08:00</updated><id>http://localhost:4000/posts/2024/03/lg-aimers-review</id><content type="html" xml:base="http://localhost:4000/posts/2024/03/lg-aimers-review/"><![CDATA[<p>지난 가을학기가 끝나갈 무렵, 아무 생각없이 2학년을 끝마친 나는 이젠 뭔가 해야한다는 초조함에 시달리고 있었다. 개별연구? 공모전? 어떤것이든 기회가 주어지면 주저없이 해야겠다는 생각으로 여러 대회도 찾아보던 와중에 우연히 광고로 <a href="https://www.lgaimers.ai/">제 4회 LG-Aimers</a>를 알게되었고 갓생 방학을 보내고자 참가하게 되었다.</p>

<h3 id="202312">2023.12</h3>

<p>LG-Aimers를 지원할 2023년 12월 당시 나는 AI 쪽으로는 거의 아는게 없던 상태였다. 프로그래밍은 예전부터 꾸준히 해왔지만 인공지능 분야로는 거의 해본적이 없었다. 다만 직전학기에 학부 기계학습 수업을 들어 기본적인 머신러닝, 딥러닝 모델에 관해 개념적으로는 나름대로 탄탄하게 알고 있었다. 내게 부족했던건 개념적인 부분보다는 실제로 라이브러리 등을 사용해서 모델을 구현하는 부분이니, LG-Aimers Phase 2가 시작되기 전에 미리 공부를 해두면 좋겠다는 생각이 들었다.(LG-Aimers Phase 1은 개념 위주라 직전 학기에 들었던 학부 수업이랑 많이 겹쳤다. 그래서 거의 안들었다). 머신러닝에 많이 사용되는 scikit-learn, 딥러닝에 자주 사용되는 Tensorflow, Keras 또는 PyTorch에 대해 잘 설명한 책이 있는지 찾아보다가 Hands-on ML이라는 유명한 책을 발견해 1월 중에 최대한 공부해보기로 했다.</p>

<h3 id="202401">2024.01</h3>
<p>LG-Aimers는 딥러닝보다는 머신러닝 위주로 운영되는것 같아 HOML에서 머신러닝 부분만 우선 공부해보기로 했다. 다행히 sklearn이 편리하게 사용할 수 있고, 설명 및 문서화가 정말 친절하게 잘 되어 있어서(이때까지 봤던 그 어떤 패키지보다 좋았다) 사용하는게 크게 어렵지 않았다. 직전학기에 학부 수업에서 개념을 열심히 공부했던 것도 큰 도움이 되었는지, 다행히 1월 중으로 Classification, Regression 에 사용되는 여러 모델 훈련 및 전체적인 ML 모델 개발 프로세스를 잘 익힐 수 있었다.</p>

<p>LG-Aimers Phase 2는 개인으로 참가도 가능했지만 팀으로 참가도 가능했다. 우연히 학교에서 LG-Aimers 준비하시는 분들이 있는 오픈채팅을 알게 되었고 그 톡방에 있던 사람들 중 두 분과 함께 셋이서 팀을 이루게 되었다. 팀이 결성된 시기는 1월 마지막 주쯤으로 Phase 2 시작 직전이기에 스터디 같은 건 많이 못하고 데이콘에 있는 이전 LG-Aimers 대회 주제에 대해 수상자 분들의 코드를 분석해보는 스터디 정도만 했다. 이때 머신러닝, 딥러닝을 이용해 문제를 해결해 나가는 과정에 대해 확실히 알게 된 것 같다.
간단히 요약해보자</p>

<ol>
  <li>EDA 및 preprocessing
    <ul>
      <li>EDA는 처음에는 용어를 보고 겁이 났지만, 알고보니 그냥 데이터셋 파악하는거였다! 였는데 정의는 간단했으나 실제로 하기에 쉽지는 않았다. 물론 특성 별 분포, 상관관계 등 기본적인 정보를 파악하는건 어렵지 않았지만 너무 단순한것들만 해서 그런지 후술하겠지만 인사이트가 보이지 않았다. Feature engineering은 깊게 들어가니 VIF 등등 생소한 개념, 방법들이 많이 나왔다. 요령도 조금 있어야 하는것 같은데 이런 면에서 아직 데이터분석에는 내가 많이 부족한 것 같다.</li>
    </ul>
  </li>
  <li>모델 설계 및 최적화
    <ul>
      <li>이 부분은 좀 자신있었다. 분류 문제를 해결한다고 치면 SVM, 여러 앙상블 모델 등등을 적용해보고 성능이 괜찮으면 튜닝으로 최적화하여 좋은 모델을 만들어 내는 과정이다.</li>
    </ul>
  </li>
</ol>

<h3 id="202402">2024.02</h3>
<p>대망의 Phase 2가 시작되었다! 이전까지는 데이콘에서 진행했는데 이번에는 엘리스에서 진행되었다. 주제는 <strong>MQL 데이터 기반 B2B 영업기회 창출 예측 모델 개발</strong>이었다. 우선 주제를 듣자마자 벙쪘던 것 같다. 마케팅 분야에는 문외한이었던 나였기에, 처음에는 주제 및 데이터셋 이해하는 것도 쉽지 않았다. 막막하긴 했지만 아래 과정대로 일단 차근차근 진행해보았다.</p>

<h4 id="1-mql이-도대체-뭐야">1. MQL이 도대체 뭐야</h4>
<p>MQL은 Marketting Qualified Lead의 약자로 회사가 투자하면 충분히 상품에 관심을 가질 만한 고객을 의미한다. 즉 이번 모델의 목적은 여러 고객의 정보가 담긴 데이터셋을 받았을 떄 MQL로 전환할 수 있을 만한 고객을 찾는 것이다. 이제 문제가 나름 선명하게 그려지기 시작했다. 이외에도 관련 마케팅 개념을 조금 알아보았으나 글이 너무 길어질 것 같아 우선 넘어가겠다.</p>

<h4 id="2-eda">2. EDA</h4>
<p>일단 csv파일을 DataFrame으로 만들고 아래와 같은 작업을 했다. DataFrame으로만 분석한건 아니고 <a href="https://dataprep.ai/">Dataprep</a>이라는 자동 EDA툴을 알게되어 기본적인건 Dataprep을 이용했고 세부적인 조정이 필요한 작업만 판다스로 직접 했다.</p>
<ol>
  <li>특성별로 unique한 값 파악하기</li>
  <li>결측치, 결측비율 확인하기</li>
  <li>수치형 특성이라면 분포 확인하기, 범주형 특성이라면 서로 다른 값들의 비율 확인하기</li>
  <li>특성 하나하나 직접 값들을 보면서 겹치거나 불필요한거 찾아내기</li>
  <li>특성 사이의 상관관계 분석하기</li>
</ol>

<p>와 같이 꽤 많은 작업을 했으나 <strong>얻은 인사이트가 거의 없다….</strong> 그나마 알게된걸 정리해보자면</p>
<ol>
  <li>특성 별로 같은 의미의 값이 서로 다르게 기록되어있다
    <ul>
      <li>OTHER, OTHERS</li>
      <li>ETC, ETC.</li>
    </ul>
  </li>
</ol>

<p>가 전부였다. 그래서 일단 저것만 적용하기로 하고 모델을 적용해보았다.</p>

<h4 id="3-모델-적용하기">3. 모델 적용하기</h4>
<p>일단 LogisticRegression을 사용했으나 당연히 택도 없었고 SVM은 너무 느렸고 결과도 별로였다. Imputing 방식도 중간에 KNNImputer, IterativeImputer로 해보았는데 그닥 나아지지 않았다. 베이스라인에서 쓰인 DecisionTreeClassifier를 튜닝해보아도 베이스라인 점수를 넘지 못했다.</p>

<p>팀원분들이 <a href="https://auto.gluon.ai/stable/index.html">Autogluon</a> 으로 여러 모델을 적용해본결과 앙상블 계열 모델이 가장 성능이 좋았다(이때가 벌써 2월 초중반이었다. 캐글, 데이콘 여러번 해보신 분들은 이때까지 앙상블 안쓰고 뭐했냐 생각하실수도 있는데…..나는 앙상블 계열부터 적용해보아야 했다는걸 이때 처음 알았다ㅠㅠ)</p>

<p>그래서 우선 RandomForestClassifier부터 적용했다. 튜닝도 열심히 해보았지만 베이스라인 못넘었다. ExtraTreesClassifier 등등 다 적용해보았는데 잘 안되었다.</p>

<p>이후 부스팅 계열을 적용해보기로 했다. sklearn에 있던 GradienBoostingClassifier, HistGradientBoostingClassifier는 그리 효과가 좋지 않았다(지금 생각해보니까 내가 제대로 못쓴거 같다). 그 이후 XGBoost, CatBoost, LightGBM을 사용해보기로 했는데 XGBoost를 사용하니까 처음으로 베이스라인을 넘었다!!!! (이때가 벌써 2월 중반)</p>

<p>감격에 겨워 정신을 못차렸지만 우선 진정하고 원인 분석을 해보았다. 보니까 이때까지 사용했던 다른 모델에서 충분한 성과가 나오지 않았던게 물론 모델의 복잡성이 낮은 걸 수도 있겠으나, 내가 class weight 설정을 제대로 하지 않았었던 게 주 원인이기도 하다(주어진 데이터셋은 0, 1이 레이블이었고 비율은 1:11로 엄청 unbalance했다). 그 이후에 XGBoost 미세 튜닝을 최대한 해보았고 public score 0.68까지 도달하였다. 아쉬웠던 부분이 XGBClassifier를 당시에 처음써보아서 파라미터 각각의 역할에 대해 잘 이해하지 못한 상황이라 효율적으로 튜닝하지 못했었다… 나중에 제대로 공부해봐야겠다.</p>

<p>그리고 CatBoostClassifier도 적용해보았는데 이번에는 튜닝도 해보니 0.72까지 퍼블릭 스코어가 올라갔다. 사실 CatBoostClassifier도 범주형 특성에 대한 처리 방식을 잘 이해하지 못해서 그냥 무작정 하이퍼파라미터 튜닝을 한거라 아쉬움이 남는다.</p>

<p>이후에 전처리 방식도 변경해보고 CatBoost 튜닝도 계속해보았지만 성능향상이 거의 없었다. (여담이지만, CatBoost는 sklearn에 내장된 RandomizedSearchCV로 튜닝하는 것이 쉽지 않았다. fit 메서드에도 인자를 주어야 하는데 이게 지원이 안되는거 같다. 그래서 optuna를 사용하는 것을 추천한다)</p>

<p>마지막 시도로 교차검증하듯이 모델을 튜닝해서 각각의 predict_proba 값을 평균내어 레이블을 결정하는 방식을 시도해서 0.74까지 올랐다. 그리고 Phase 2도 종료되었다.</p>

<p>결과는 첫 시도치고 좋지 않았나 싶다. 우선 private score (final score) 기준 91위로 리더보드에서 밀려나지는 않았다ㅋㅋㅋㅋ public score가 100위였는데 오버피팅을 잘 피한덕분인지 순위가 조금 올랐다.</p>

<h3 id="앞으로-해야할-것-배운점">앞으로 해야할 것, 배운점</h3>
<ul>
  <li>XGBoost, CatBoost, LightGBM 개념적으로 이해하기</li>
  <li>Feature engineering 기법 배우기(feature selection, 파생변수 등등)</li>
  <li>unbalanced dataset 처리하는 방법</li>
  <li>sklearn 내장 패키지가 아니거나 모델이 좀 복잡해서 내장 튜닝 패키지 적용이 어려우면 optuna를 쓰자</li>
  <li>데이콘, 캐글 몇개 더 해보면서 경험 쌓기</li>
</ul>]]></content><author><name>Sangoh Kim</name><email>tkddh1109 (at) kaist.ac.kr</email></author><category term="LG-Aimers" /><category term="AI" /><category term="ML" /><category term="DL" /><summary type="html"><![CDATA[지난 가을학기가 끝나갈 무렵, 아무 생각없이 2학년을 끝마친 나는 이젠 뭔가 해야한다는 초조함에 시달리고 있었다. 개별연구? 공모전? 어떤것이든 기회가 주어지면 주저없이 해야겠다는 생각으로 여러 대회도 찾아보던 와중에 우연히 광고로 제 4회 LG-Aimers를 알게되었고 갓생 방학을 보내고자 참가하게 되었다.]]></summary></entry></feed>